{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Bt9E1ouwk9_",
        "outputId": "ce4526ac-71bb-4bb2-8046-c899b47c4957"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing train: 1434 images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1434/1434 [28:12<00:00,  1.18s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing val: 409 images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 409/409 [07:36<00:00,  1.12s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing test: 206 images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 206/206 [03:52<00:00,  1.13s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset created at /content/drive/MyDrive/AOLP_YOLO\n",
            "Structure:\n",
            "Train: 1434\n",
            "Val:   409\n",
            "Test:  206\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "img_path = '/content/drive/MyDrive/Phase2_Results'\n",
        "label_path = '/content/drive/MyDrive/AOLP_Dataset'\n",
        "two_plates_file = '/content/drive/MyDrive/AOLP_Dataset/Subset_LE/two_plates.txt'\n",
        "\n",
        "output_dir = '/content/drive/MyDrive/AOLP_YOLO'\n",
        "subsets = [\"Subset_AC\", \"Subset_LE\", \"Subset_RP\"]\n",
        "\n",
        "# Split ratios (test ratio is the remainder)\n",
        "train = 0.7\n",
        "val = 0.2\n",
        "\n",
        "# Helper functions\n",
        "\n",
        "def convert_box(size, box):\n",
        "    \"\"\"\n",
        "      Converts top-left/bottom-right to YOLO (x_center, y_center, width, height) normalised\n",
        "      size: (width, height) of image\n",
        "      box: (x_min, y_min, x_max, y_max)\n",
        "    \"\"\"\n",
        "    dw = 1. / size[0]\n",
        "    dh = 1. / size[1]\n",
        "\n",
        "    x_center = (box[0] + box[2]) / 2.0\n",
        "    y_center = (box[1] + box[3]) / 2.0\n",
        "    w = box[2] - box[0]\n",
        "    h = box[3] - box[1]\n",
        "\n",
        "    x_center = x_center * dw\n",
        "    w = w * dw\n",
        "    y_center = y_center * dh\n",
        "    h = h * dh\n",
        "    return (x_center, y_center, w, h)\n",
        "\n",
        "# def read_groundtruth(txt_path):\n",
        "#     \"\"\"Reads the 4-line coordinate file.\"\"\"\n",
        "#     if not os.path.exists(txt_path):\n",
        "#         return None\n",
        "#     with open(txt_path, 'r') as f:\n",
        "#         lines = f.readlines()\n",
        "#         # Parse lines, handling scientific notation if present\n",
        "#         try:\n",
        "#             coords = [float(x.strip()) for x in lines]\n",
        "#             # Format is: x1, y1, x2, y2\n",
        "#             return [coords[0], coords[1], coords[2], coords[3]]\n",
        "#         except ValueError:\n",
        "#             print(f\"Error parsing {txt_path}\")\n",
        "#             return None\n",
        "\n",
        "def read_groundtruth(txt_path):\n",
        "    \"\"\"\n",
        "      Reads the 4 line coordinate file (x1, y1, x2, y2)\n",
        "    \"\"\"\n",
        "    if not os.path.exists(txt_path):\n",
        "        return None\n",
        "    with open(txt_path, 'r') as f:\n",
        "        # Filter out empty lines just in case\n",
        "        lines = [l.strip() for l in f.readlines() if l.strip()]\n",
        "\n",
        "        try:\n",
        "            coords = [float(x) for x in lines]\n",
        "\n",
        "            # To confirm we actually got 4 coordinates\n",
        "            if len(coords) < 4:\n",
        "                print(f\"Skipping {txt_path}: Found {len(coords)} lines, expected 4.\")\n",
        "                return None\n",
        "\n",
        "            x1, y1, x2, y2 = coords[0], coords[1], coords[2], coords[3]\n",
        "\n",
        "            # Logic checking: Ensure x2 > x1 and y2 > y1 (positive width/height)\n",
        "            # There's chances that the data can be malformed\n",
        "            if x2 <= x1 or y2 <= y1:\n",
        "                # Fix swapped coordinates\n",
        "                x1, x2 = min(x1, x2), max(x1, x2)\n",
        "                y1, y2 = min(y1, y2), max(y1, y2)\n",
        "\n",
        "            return [x1, y1, x2, y2]\n",
        "\n",
        "        except ValueError:\n",
        "            print(f\"Error parsing numbers in {txt_path}\")\n",
        "            return None\n",
        "\n",
        "# Main method\n",
        "def main():\n",
        "    # Load two plates list\n",
        "    double_plates_ids = set()\n",
        "    if os.path.exists(two_plates_file):\n",
        "        with open(two_plates_file, 'r') as f:\n",
        "            # Source 2 format implies simple list of IDs\n",
        "            lines = f.readlines()\n",
        "            for line in lines:\n",
        "                clean_id = line.strip().split()[0] # Take first part if there's extra text\n",
        "                if clean_id.isdigit():\n",
        "                    double_plates_ids.add(clean_id)\n",
        "    else:\n",
        "        print(\"two_plates.txt not found, assuming no double plates\")\n",
        "\n",
        "    # Collect all data entries\n",
        "    # Format: {'src_img': path, 'src_labels': [path1, path2], 'dst_name': string}\n",
        "    dataset = []\n",
        "\n",
        "    for subset in subsets:\n",
        "        img_dir = os.path.join(img_path, subset)\n",
        "        # Handle naming difference, image folder is Subset_AC, groundtruth is in Subset_AC/groundtruth_localization\n",
        "        lbl_dir = os.path.join(label_path, subset, \"groundtruth_localization\")\n",
        "\n",
        "        if not os.path.exists(img_dir):\n",
        "            print(f\"Skipping {subset}, path not found: {img_dir}\")\n",
        "            continue\n",
        "\n",
        "        images = [f for f in os.listdir(img_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "\n",
        "        for img_file in images:\n",
        "            file_id = os.path.splitext(img_file)[0]\n",
        "\n",
        "            src_img_path = os.path.join(img_dir, img_file)\n",
        "\n",
        "            # Identify Label Files\n",
        "            label_files = []\n",
        "\n",
        "            # Check for standard label\n",
        "            std_lbl_path = os.path.join(lbl_dir, f\"{file_id}.txt\")\n",
        "            if os.path.exists(std_lbl_path):\n",
        "                label_files.append(std_lbl_path)\n",
        "\n",
        "            # Check for double plates (Only for LE has double plates cases)\n",
        "            if subset == \"Subset_LE\" and file_id in double_plates_ids:\n",
        "                second_lbl_path = os.path.join(lbl_dir, f\"{file_id}_2.txt\")\n",
        "                if os.path.exists(second_lbl_path):\n",
        "                    label_files.append(second_lbl_path)\n",
        "\n",
        "            if not label_files:\n",
        "                # Some images might not have labels (negatives), handle as background\n",
        "                pass\n",
        "\n",
        "            dst_filename = f\"{subset}_{img_file}\"\n",
        "\n",
        "            dataset.append({\n",
        "                'src_img': src_img_path,\n",
        "                'labels': label_files,\n",
        "                'dst_name': dst_filename\n",
        "            })\n",
        "\n",
        "    # Shuffle and split\n",
        "    random.seed(42)\n",
        "    random.shuffle(dataset)\n",
        "\n",
        "    total_count = len(dataset)\n",
        "    train_end = int(total_count * train)\n",
        "    val_end = train_end + int(total_count * val)\n",
        "\n",
        "    splits = {\n",
        "        'train': dataset[:train_end],\n",
        "        'val': dataset[train_end:val_end],\n",
        "        'test': dataset[val_end:]\n",
        "    }\n",
        "\n",
        "    for split_name, split_data in splits.items():\n",
        "        img_save_dir = os.path.join(output_dir, \"images\", split_name)\n",
        "        lbl_save_dir = os.path.join(output_dir, \"labels\", split_name)\n",
        "        os.makedirs(img_save_dir, exist_ok=True)\n",
        "        os.makedirs(lbl_save_dir, exist_ok=True)\n",
        "\n",
        "        print(f\"Processing {split_name}: {len(split_data)} images...\")\n",
        "\n",
        "        for entry in tqdm(split_data):\n",
        "            # Read Image to get dimensions\n",
        "            img = cv2.imread(entry['src_img'])\n",
        "            if img is None:\n",
        "              continue\n",
        "            height, width = img.shape[:2]\n",
        "\n",
        "            # Copy Image with retry mechanism\n",
        "            copy_succeeded = False\n",
        "            max_retries = 3\n",
        "            for attempt in range(max_retries):\n",
        "                try:\n",
        "                    shutil.copy(entry['src_img'], os.path.join(img_save_dir, entry['dst_name']))\n",
        "                    copy_succeeded = True\n",
        "                    break\n",
        "                except FileNotFoundError as e:\n",
        "                    print(f\"Warning: FileNotFoundError during copy of {entry['src_img']} to {os.path.join(img_save_dir, entry['dst_name'])}. Attempt {attempt + 1}/{max_retries}.\")\n",
        "                    if attempt < max_retries - 1:\n",
        "                        time.sleep(1) # Wait a bit before retry\n",
        "                    else:\n",
        "                        print(f\"Error: Failed to copy {entry['src_img']} after {max_retries} attempts. Skipping this image and its labels.\")\n",
        "\n",
        "            if not copy_succeeded:\n",
        "                continue # Skip to the next entry if image copy fail\n",
        "\n",
        "            # Process Labels\n",
        "            yolo_lines = []\n",
        "            for lbl_path in entry['labels']:\n",
        "                box_coords = read_groundtruth(lbl_path) # [x1, y1, x2, y2]\n",
        "                if box_coords:\n",
        "                    # Convert to YOLO (x_c, y_c, w, h)\n",
        "                    yolo_box = convert_box((width, height), box_coords)\n",
        "                    # Class ID is 0 (license_plate)\n",
        "                    yolo_lines.append(f\"0 {yolo_box[0]:.6f} {yolo_box[1]:.6f} {yolo_box[2]:.6f} {yolo_box[3]:.6f}\")\n",
        "\n",
        "            # Write label file\n",
        "            dst_lbl_name = os.path.splitext(entry['dst_name'])[0] + \".txt\"\n",
        "            with open(os.path.join(lbl_save_dir, dst_lbl_name), 'w') as f:\n",
        "                f.write('\\n'.join(yolo_lines))\n",
        "\n",
        "    print(f\"\\nDataset created at {output_dir}\")\n",
        "    print(f\"Structure:\")\n",
        "    print(f\"Train: {len(splits['train'])}\")\n",
        "    print(f\"Val:   {len(splits['val'])}\")\n",
        "    print(f\"Test:  {len(splits['test'])}\")\n",
        "\n",
        "    # Create data.yaml file\n",
        "    yaml_content = f\"\"\"\n",
        "path: /kaggle/input/aolp-yolo/AOLP_YOLO\n",
        "train: images/train\n",
        "val: images/val\n",
        "test: images/test\n",
        "\n",
        "nc: 1\n",
        "names: ['license_plate']\n",
        "    \"\"\"\n",
        "\n",
        "    with open(os.path.join(output_dir, \"data.yaml\"), \"w\") as f:\n",
        "        f.write(yaml_content)\n",
        "\n",
        "\n",
        "main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!find /content/drive/MyDrive/AOLP_YOLO -type f -iname \"*.jpg\" | wc -l\n",
        "!find /content/drive/MyDrive/AOLP_YOLO -type f -iname \"*.txt\" | wc -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kFQ9siY9pIl",
        "outputId": "66e78656-effb-406f-dc8c-4c36e38dab56"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2049\n",
            "2049\n"
          ]
        }
      ]
    }
  ]
}